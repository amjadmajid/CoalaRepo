Our implementation of \sys makes no system assumptions: we execute \sys on a \emph{real} low-power embedded computing platform powered by a \emph{real} intermittent energy harvesting source. This approach shall lead to undisputed set of \sys performance metrics. 

\subsection{Intermittent Platform and Hardware Toolchain}
\label{sec:results_hardware_software}

We evaluated \sys in two power supply environments: (i)  \emph{intermittent} and (ii) \emph{fixed} (to benchmark the intermittent power supply results). In the experiments with intermittent power supply, we evaluated \sys using a WISP\,5.1~\cite{wisp5,wisp}---energy-harvesting platform build around a MSP430FR5969~\cite{wolverine} MCU with with 64\,kB of non-volatile (FRAM) memory and and 2\,kB of volatile memory (SRAM). MCU was operating at 1\,MHz clock cycle. We powered the WISP using RF signal generator~\cite{} \todo{Add reference to signal generator}{Przemek} emitting 20\,dBm sinusoidal wave at 915\,MHz.  Signal generator was connected to the Liard RFMAX S9028PCRJ 8\,dBic antenna~\cite{atlas2015}. For distance-controlled experiments, we affixed WISP at two paper protrusions around 10\,cm from the surface of the table (parallel to, and at the edge of, the table surface). Antenna of the signal generator was facing WISP directly and located at three distances, $d=\{15, 30, 50\}$\,cm, from WISP. For the task downscaling experiments, an additional distance of $d=60$\,cm was considered. Both antennas were parallel to each other and no physical objects were located between the WISP and the signal generator antenna. For continuous power experiments we used an alternative setup with MSP-EXP430FR5969 launchpad~\cite{MSP-EXP430FR5969_launchpad}, which had the same MCU as WISP. In all the experiments the timing measurements were performed using either the Saleae~\cite{saleae} logic analyzer (for intermittent power experiments) or TI Code Composer Studio (for fixed power experiments). \todo{provide version and more details on TI CCS}{Przemek} Both type of experiments are explained in the following section.

\subsection{Software Benchmarks}
\label{sec:software_benchmarks}

\begin{table}
	\centering
	\footnotesize
	\begin{tabular}{| r | p{0.85\columnwidth} |}
		\hline
		Application & Description \\
		\hline\hline
		\textbf{ar} & nearest neighbor classification of randomly generated data modeling a three-axis accelerometer\\
		\hline
		\textbf{bc} & counts bits in byte pseudo-random string using several algorithms, and compares results for correctness\\
		\hline
		\textbf{cuckoo} & Bloom-filter-like Cuckoo filter: first hashes a sequence of pseudo-random numbers, then queries the filter to recover the sequence\\
		\hline
		\textbf{dijkstra} &  Dijkstra algorithm executed continously on a predefined adjecency matrix\\
		\hline
		\textbf{fft} & continuously repeating Fast Fourier Transform on three pre-generated 128 sample vector\\
		\hline
		\textbf{sort} & selection sort algorithm on a fixed sequence of numbers\\
		\hline
	\end{tabular}
\caption{Suite of benchmark applications used in evaluating \sys performance. All applications have been chosen from MiBench testing suite~\cite{mibench,hicks_mibench2_2016}.\todo{Consider adding more information here}{Przemek, Carlo}}
\label{table:benchmark_table}
\end{table}

We evaluated \sys using six benchmarks summarized in Table~\ref{table:benchmark_table}, with their implementation is available via~\cite{coala_website}. Five benchmarks originate from the MiBench testing suite~\cite{mibench,hicks_mibench2_2016}: three benchmarks (\textbf{ar}, \textbf{bc}, \textbf{cuckoo}) were already implemented by Chain~\cite{chain} and Alpaca~\cite{alpaca}, while two (\textbf{dijkstra}, \textbf{fft}\footnote{Specifically, we re-implemented FFT based on the TI's accelerated FFT library~\cite{}.\todo{add reference}{Przemek}}) are added as new. The final one (\textbf{sort}) has been written from scratch. \todo{justify the selection of these benchmarks}{Przemek, Carlo, Amjad, Brandon} All applications were compiled using GCC version 3.8.0. \todo{Check if this still holds. provide optimization flag}{Przemek} 

%Specifically, we have implemented three benchmarks used by Chain~\cite{chain} and Alpaca~\cite{alpaca} (source code is accessible~\cite{coala_website}), namely: \textbf{ar}: nearest neighbor classification of randomly generated data modeling a three-axis accelerometer; \textbf{bc}: counts bits in byte pseudo-random string using several algorithms, and compares results for correctness; \textbf{cuckoo}: Bloom-filter-like Cuckoo filter that first hashes a sequence of pseudo-random numbers, then queries the filter to recover the sequence. Additionally, we have ported three new benchmarks from~\cite{mibench}, namely: \textbf{dijkstra}: Dijkstra algorithm executed continously on a predefined adjecency matrix; \textbf{fft}: continuously repeating Fast Fourier Transform on three pre-generated 128 sample vector; and \textbf{sort}: selection sort algorithm on a fixed sequence of numbers. \todo{justify the selection of these benchmarks}

\textbf{Comparison with Alpaca and Alpaca Compiler Limitations.} We compare \sys against state-of-the-art task-based runtime Alpaca~\cite{alpaca}. For correct comparison, all benchmarks of \sys were divided into tasks in the same way as Alpaca. Since original Alpaca runtime was written in Clang, we had to transform every benchmark manually into GCC-complaint code. \todo{Provide more information about porting to GCC from LLVM}{Brandon, Carlo} This was a time-consuming process since a programmer needs to identify WAR dependencies \todo{check if we use WAR or write-after-read or anything else}{Przemek}, then change variables' names and modify instructions accordingly. Nota bene, our experiments based on the benchmarks we used here show that Alpaca compiled with GCC is about 30\%-40\% faster than Alpaca compiled with Clang. \todo{Provide concrete numbers for all applications}{Amjad} The speed improvement we got for Alpaca with GCC is however sacrificed by the above-mentioned error-prone manual code transformation process for which no compiler support exists thus far. \sys \emph{does not require any of such transformations}.

\textbf{Comparison of \sys against other Systems.} We do not compare \sys against Chain~\cite{chain}, another task-based system, which is inferior to Alpaca in its performance. Also, we do not compare \sys to checkpointing-based systems, such as DINO~\cite{dino} or Mementos~\cite{mementos} (cf. Section~\ref{sec:background_consistency}). \todo{Provide reasons why we do not compare against checkpointing}{Brandon}.