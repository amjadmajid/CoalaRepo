When incoming energy is sufficient to run multiple consecutive tasks,
committing state after each task is wasteful. \sys mitigates this
waste by deferring the expensive commits and performing them in a
batch. In the resulting execution, several tasks are \emph{merged} into a
single virtual task---a process we call \emph{coalescing}. 
%
When $N$ tasks are coalesced, $N-1$ boundaries are crossed and some number of
pages are dirtied. The first $N-2$ executions of \transition statement skip
committing dirty pages to non-volatile memory, leaving the work of committing
pages modified by any of the $N$ tasks to the statement $N-1$.
Coalescing is likely to reduce the total number of non-volatile memory
accesses, because when coalesced tasks access the same pages of data, only the
last version of the page needs to be committed.

\textbf{Trade-off between Speed and Wasted Effort.} \sys can coalesce an
arbitrary number of consecutive tasks. However, as more tasks coalesce, their
collective commit overhead amortizes better, but the risk of wasting work also
increases. If power fails during a long sequence of coalesced tasks, execution
will restart from the last commit, i.e. the first task in the sequence, losing
the progress made by any of the coalesced tasks.  The challenge to coalescing
tasks is determining how many tasks to coalesce before committing.
%
%During execution, an executing task is either a {\em coalesced} task, which
%does not commit its state before transitioning or a {\em committing} task,
%which does commit its state before transitioning.

\textbf{Task Coalescing Strategies.} 
A good coalescing strategy must moderate the risk of wasted work and capitalize
on benefits of deferred commits by adapting the target size of the dynamic task
to the energy available at runtime.
%
The general structure of our strategies is to increase the target task size by
some positive delta $C_\text{up}$ after the dynamic coalesced task completes,
and decrease it by some negative delta $C_\text{down}$ upon a reboot after a
power failure.
%
The choice of $C_\text{up}$ and $C_\text{down}$, including their units, defines
the strategy and its performance.
%
For example, a naive strategy that fixes $C_\text{up}$ and $C_\text{down}$ to
``one static task``, will be very slow to react to changes in incoming energy,
since its dynamic task size can only change by the size of one (small) static
task per charge-discharge cycle.
%
Working from these observations, we propose and evaluate two coalescing
strategies for \sys:

\begin{enumerate}
	\item \textbf{Interrupt History Coalescing (HDC):} when more tasks are coalesced without power interrupt, $C_U$ increases, and $C_D$ increases, as more task are interrupted before committing; and 
	\item \textbf{Weighted Interrupt History Coalescing (WHDC):} where coalescing strategy follows the one of HDC, while also taking into account the \emph{expected execution time} of each task in the application.
\end{enumerate}

\subsection{Power Interrupt History Coalescing}

With this strategy \sys calculates only one parameter $C=C_U=C_D$ based on the number of tasks completed, until $t$th task commit, $S_t$, during the current operational period. \sys begins execution in a coalesced task with $S_t=0$. When $S_t=C_{t-1}-1$ coalesced tasks have been executed without power interrupt (where $C_{t-1}$ defines $C$ until $t-1$ task commit) a task commit follows. After each commit, \sys assigns new coalescing factor as $C_{t}=\lceil \sum_{k=1}^{t}S_{k-1}/2\rceil$. This implies that if more tasks complete in an operating period, \sys attempts to coalesce more tasks. However, tasks coalescing are increased by a half the speed of the successful task completion. This way we adapt to the coalescing speed/wasted effort trade-off: at the potential power interrupt \sys does not immediately reduce coalescing factor to one, and with successful page commit of coalescing task, \sys gradually increases coalescing factor. In both cases \sys reduces the effect of outliers, i.e. short bursts of energy or short bursts of frequent power interrupts.

%\textbf{Task Coalescing Illustration.} Figure~\ref{fig:coalescing_example_states} shows a sequence of three tasks executing in \sys. At left, there is no coalescing and tasks incur the cost of commit at each transition. The center shows the same tasks executing as coalesced groups of two tasks $C=2$, avoiding one commit. At right, \sys coalesces three tasks ($C=3$) avoiding two commits. Figure~\ref{fig:coalescing_example_flowchart} shows how \sys adapts the value of $C$ based on $S$. \sys executes tasks in the first operating period, with $C$ equal to half the number of tasks completed in the prior execution period. In the example, $C$ starts at eight. After completing eight tasks, \sys commits and reduces $C$ by half to four. \sys completes two of four tasks and power fails.  During the operating period, \sys executed a total of ten tasks (i.e., $S=10$) and when \sys restarts, $C$ is assigned to five (i.e., half of $S$). \sys completes the five coalesced tasks $S=5$ and after committing, assigns $C$ to half of $S$, which is three (after rounding up). \sys coalesces three tasks and again commits.  At this point, $S=8$; \sys assigns $C=4$ and execution continues.

\subsection{Weighted Power Interrupt History Coalescing}

The previous coalescing strategy is oblivious to the task size. Although many tasks can be coalesced, their non-equal size will determine that some coalesced tasks will be more susceptible to power interrupts than others. To understand that effect we provide the following illustration. 

\textbf{Task Size Profiling.} We have used a set of program benchmarks (refer to Section~\ref{sec:results_software} for details and to the beginning of Section~\ref{sec:methodology_evaluation} for system setup). Each benchmark was run for predefined period of time (in case of Figure~\ref{fig:task_profiling} 10\,seconds), on non-intermittent power, and at each task evocation, its execution time was measured. If a task was evoked more than once, longer execution time replaced the short one---this way we obtained conservative values of task sizes. At the end of task measurement, normalized integer values of task execution for task $x$, $W_x$, are collected---the shortest one being one task, the longest one $W_{x,\max}$ (in case of Figure~\ref{fig:task_profiling} $W_{x,\max}=5$). Result of the task size measurement is provided in Figure~\ref{fig:task_profiling}. We observe huge variations of task sizes---both within a benchmark, as well per benchmark, which calls for the use of this information in coalescing.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{figures/TskDist.pdf}%coalescing_timeline
	\caption{Result of benchmark applications (Section~\ref{sec:results_software}) task size measurement, measured in the number of instruction cycles. We observe very large variations of task sizes per each benchmark. \todo{Describe X axis, no capitals in titles - except first word; markers in addition to colors per app; remove 4.7}{Amjad}}
	\label{fig:task_profiling}
\end{figure}

With the task size information, in the second (weighted) coalescing strategy an application needs to be profiled, as above, before it is loaded to the intermittently-powered device. Then the process of coalescing is the same as for the (non-weighted) power interrupt history coalescing, with the exception that $S_t=W_x \times S_t$, i.e. number of traversed tasks before commit are a function of their size.

%\begin{figure}
%	\centering
	%\subfloat[\sys coalesces consecutive tasks.]{\includegraphics[width=\columnwidth]{figures/coalescing_states}\label{fig:coalescing_example_states}}\\
	%\subfloat[\sys dynamically adapts the amount of coalescing.]{\includegraphics[width=\columnwidth]{figures/coalescing_timeline}\label{fig:coalescing_example_flowchart}}
	%\caption{\sys coalesces tasks to avoid overheads.}
	%\label{fig:coalescing_example}
%\end{figure}

%However, it takes a conservative approach by making the virtual task size equal
%to the half of the number of successfully executed real tasks before the last
%power interrupt (see lines~\ref{algo:coalescing:executionHistory1},
%\ref{algo:coalescing:executionHistory2} of Algorithm~\ref{algo:coalescing}). 
%
%We
%advocate for the algorithm conservative approach by the following two reasons:
%(i) the power interrupts are not uniformly distributed over the tasks; and (ii)
%the re-execution penalty, in case of a power interrupt, grows linearly with the
%size of a virtual task. 
%
%Furthermore, the algorithm considers the charging rate
%by allowing the real tasks counter (RTC), which represents the execution
%history between the last two power interrupts, to increase from one up to
%multiple virtual tasks (see line~\ref{algo:coalescing:realTaskCounter} of
%Algorithm~\ref{algo:coalescing}). 
%
%As a consequence, the virtual task size
%changes rapidly (since it is half of the execution history) in response to the
%change in the charging rate. 
%
%However, the algorithm sets a limit to the size of
%the virtual task for these two reasons: (i) having an infinity virtual task
%size, results in a certain computation progress loss; and (ii) the benefit of
%task merging is governed by the diminishing return principle (which will be
%demonstrated experimentally in Section~\ref{sec:results_coalescing}).
%
%The algorithm protects itself from power interrupts by going into three stages:
%(i) virtual progressing, where the operations are done on the volatile memory
%(see
%lines~\ref{algo:coalescing:virtualProgressing1}--\ref{algo:coalescing:virtualProgressing2}
%of Algorithm~\ref{algo:coalescing} ); 
%(ii) transition stage, where the volatile
%state is moved to a temporary persistent buffer. 
%
%Until the end of the second
%stage if a power is interrupted, then all the virtual progress will be
%cancelled and the virtual task will re-executed and re-initialized from a
%consistent input (see line~\ref{algo:coalescing:virtualProgressing1} of
%Algorithm~\ref{algo:coalescing}); 
%
%and (iii) persistent commit stage, upon
%entering this stage the algorithm will make a firm transition (see
%lines~\ref{algo:coalescing:firmTransition1},
%\ref{algo:coalescing:firmTransition2} of Algorithm~\ref{algo:coalescing}) and
%it will not go back to the other stages unless all the data is committed from
%the persistent buffer to non-volatile memory. 
%
%Since the data is being moved in one direction and from a persistent location,
%power interrupt is tolerable at this stage. 

%\begin{algorithm}[t]
%	\caption{\sys task coalescing mechanism}
%	\label{algo:coalescing}
%	\scriptsize
%	\begin{algorithmic}[1]
%		\State $\text{p}$  \Comment{Indicates persistent variables, initialized \textbf{only} during device programming}
%		\State $\text{RT} \in \{\sys~\text{static tasks}\}$  \Comment{Real task}
%		\State $\text{VT} \subset \{~\text{RT's}\}$  \Comment{Virtual task}
%		\State $\text{RTC}$  \Comment{RT counter}
%		\State $\text{VTC}$  \Comment{VT counter}
%		% \State $|\text{VT}|$ \Comment{VT size measured in RT}
%		\State $\text{TVT}$ \Comment{Temporary VT}
%		\State $\text{VT}_{\max}$ \Comment{Maximum VT size measured in RT (coalescing upper bound)}
%		\vspace{0.1cm}
%		
%		\State $\text{p RTC} = x $ 
%		\State $\text{p VT}_{\max} = y$
%		\State $\text{p VT} = \text{RT}$ 
%		\State $\text{p TVT} = \text{VT} $ 
%		\State $\text{VTC} = 0 $ 
%		\vspace{0.1cm}
%
%		\Function{scheduler}{\null}
%
%			\State $\text{VTC} = \text{RTC/2} $  \label{algo:coalescing:executionHistory1}
%			\State $\text{RTC} = 0 $
%			\State $\text{RT} = \text{VT}$ \Comment{Recover virtual state} \label{algo:coalescing:virtualProgressing1}
%			\If{commiting}
%				\State $\text{RT}=\text{TVT}$
%				\State $\texttt{goto} \ \ \ref{commitStage}$ \label{algo:coalescing:firmTransition1}
%			\EndIf
%			\vspace{0.1cm}
%
%			\While {True}
%				\While{$\text{VTC}--$}
%					\Function{execute}{$\text{RT}$}
%					\EndFunction
%					\If{$\text{RTC} < \text{VT}_{\max}$}
%						\State $\text{RTC}++$  \label{algo:coalescing:realTaskCounter}
%					\EndIf
%					\State $\text{RT} \leftarrow \text{RT}_{next}$ \Comment{Virtual progressing}
%				\EndWhile        \label{algo:coalescing:virtualProgressing2}
%
%				\State \Comment{Virtual task is finished}
%				\State $\text{Data} \rightarrow \text{pTempBuf}$ \Comment{pTempBuf: persistent temporary buffer}
%				\State $\text{TVT} = \text{RT}$ 
%				\State $\text{commiting} = \text{True}$ \label{algo:coalescing:firmTransition2}
%				\State 
%				\State $\text{VT} = \text{TVT}$ \label{commitStage}
%				\State $\text{pTempBuf} \rightarrow \text{FRAM}$ 
%				\State $\text{VTC} = \text{RTC/2}$ 		\Comment{Set VT size} \label{algo:coalescing:executionHistory2}
%				\State $\text{commiting} = \text{False}$ 
%
%			\EndWhile
%
%		\EndFunction
%			
%	\end{algorithmic}
%\end{algorithm}

%\subsection{Power Interrupt Immune Scheduler}
%
%\input{relativeJumpAlgo.tex} %Task jumping algorithm
%
%It utilizes a persistent circular buffer (i.e. persistent linked list) to keep the state of a program across power failures. \sys provides an API to enable a programmer to have a full control over the execution flow of the program, i.e. (un)blocking a task or re-execute the same task which is particularly important in the intermittent execution to emulate a persistent loop. \todo{Expand this section}{Amjad}
%
%\begin{algorithm}
%	\caption{Opportunistic virtual Task size}
%	\label{algo:fixVirtTask}
%	\scriptsize
%	%\small
%	\begin{algorithmic}[1]
%		\State $VT \subset \text{\{\sys Tasks\}} $  \Comment{$VT:$ Virtual Task}
%		\State VTS : VT size
%		\vspace{0.1cm}
%		
%		\While {$True$}
%		\State $VT \leftarrow VT_{next}$
%		\vspace{0.1cm}
%		\While {execute $VT$} 
%		\If { $\text{power failed twice}$ }				
%		\State $VTS--$  
%		\EndIf
%		\EndWhile
%		
%		\vspace{0.1cm}
%		\If {$ \text{All tasks executed}$}
%		\State $VTS++$
%		\EndIf
%		\EndWhile
%	\end{algorithmic}
%\end{algorithm}
