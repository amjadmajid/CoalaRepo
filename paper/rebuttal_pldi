>> Reviewer A

[A.a] Overemphasis on Chain 

Coala uses a fundamentally different design than Chain, jettisoning fixed
static tasks in favor of our coalescing model. Chain is a reasonable, recent
point of comparison and intellectual basis for Coala.


[A.b] Why geometric adjustment? 

Linearly adjusting boundaries may be slow and lead to repeated failures before
finding a coalescing factor that works.  Geometric adjustment varies the
coalescing factor more quickly.

[A.c] Alpha sensitivity; power failure rates at 1 Hz and 10 Hz

Poor/good harvesting conditions always result in a short/long execution
history. Coala uses the history as environment indicator. Therefore, it
dynamically coalesce a few/large number of tasks in poor/good harvesting
conditions. We experimentally set alpha to be 0.5.

[A.d] Coala is compared to Chain only, what about checkpointing and unmodified C?

The original Chain paper compared to these other approaches and unmodified C,
and we compared to Chain.

>> Reviewer B

[A.b] Comparison to Alpaca. 

Alpaca was published after we submitted this paper and we could not add it as a
basis for comparison.   We expect that Coala's main ideas could be applied in
Alpaca as well.


Reviewer D

[D.a] SLOC column Table 3

The difference in the number of lines of code comes from the fact that the Chain programmer must define and manipulate channels.  In Coala, memory protection is abstracted from the programmer and managed by Coala.


Reviewer C

[C.a] Task definition

We give an overview of task semantics in lines 96-102 and reference prior work [10] that introduces the concept. 

[C.b] Comparisons to prior work 

See responses to Reviewers A and B. 

[C.c] Evaluating compiler-generated tasks with continuous power

We compare the performance of automatically generated code to manually
decomposed code without the unpredictable time cost of power failures.  Other
experiments compare for harvested energy.

[C.d] What about timeliness requirements?

Timeliness was studied by recent work (Mayfly) that is complementary to the ideas in Coala. 

[C.e] History-ware coalescing algorithm growth is unbounded 

This parameter is bounded in our prototype.

[C.g] components of reported execution time?

We report the execution time of committing dirty pages and copying pages to the SRAM. 

[C.h] perform evaluations to test hypothesis and explore scientific questions

The scientific question addressed by Coala is whether adding dynamism (in the form of coalescing) to a static, task-based intermittent computing system is more efficient or simpler to program than a plain, static task system.  Practically, Coala decomposes the entwined problems of forward progress and memory protection for intermittent executions, addressing each with a novel system mechanism. 
