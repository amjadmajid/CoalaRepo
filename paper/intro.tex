Advances in processor efficiency along with the development of energy-harvesting power systems has created a new category of devices that require neither a battery nor a tethered power supply~\cite{prasad_comst_2014,lucia_snapl_2017,soyata_csm_2016}. These devices operate entirely using energy extracted from their environment, such as RF energy~\cite{rf_powered_computing_gollakota_2014}, photovoltaic components~\cite{margolies_infocom_2016,margolies_tosn_2016}, and vibration~\cite{gorlatova_sigmetrics_2014}. Incorporating compute, storage, sensing, and communication hardware~\cite{wisp5,moo}, such energy-independent devices are a promising underlying technology for applications in emerging areas such as Internet of Things (IoT)~\cite{ku_cst_2016}, in-body~\cite{nadeau_naturebio_2017} and on-body~\cite{bandodkar_electroanalysis_2015} medical systems, and energy-harvesting nano-satellites~\cite{kicksat}.

While promising, energy-harvesting devices present a unique design challenge in
that they operate only {\em intermittently} when energy is available~\cite{hicks_isca_2017,lucia_snapl_2017}. An
energy-harvesting device buffers energy from its environment, e.g., in a
capacitor~\cite[Fig. 3]{gorlatova_tmc_2013},~\cite[Fig. 1]{gunduz_commag_2014}. When a threshold quantity of energy accumulates, the device begins operating. Harvestable energy sources typically produce relatively very little power compared to a platform's operating power level---compare for instance~\cite[Table III and V]{prasad_comst_2014} with~\cite[Table I]{carrano_cst_2014}. A devices operates for a brief period of time and when buffered energy is depleted, shuts down and begins recharging to operate again later. As an example, inter-task time may even exceed 20\,s for wireless energy-harvesting battery-less vivo digestive tract monitoring system~\cite[Fig. 3c]{nadeau_naturebio_2017}. On top of that, charge and discharge times vary by device and some of them~\cite{wisp} may fail $\approx$10 to $\approx$100 times per second~\cite[Fig. 1]{tan_infocom_2016},~\cite[Fig. 1]{mementos},~\cite[Fig. 3]{nvp}.

Software in an energy-harvesting system operates according to the {\em
intermittent execution model}~\cite{dino,lucia_snapl_2017}, with bursts of
execution interrupted by failure periods.  When power fails, a device loses its
volatile state, i.e., registers, stack, SRAM, and retains its non-volatile
state, i.e., FRAM, Flash. While capturing periodic
checkpoints~\cite{mementos,quickrecall} and sleep
scheduling~\cite{dewdrop,hibernus,hibernusplusplus} help to preserve execution
progress, failures can leave volatile and non-volatile state inconsistent,
leading to unrecoverable failures~\cite{mspcdino,edb}. 

There are two main approaches for dealing with data inconsistency for
intermittently-powered devices: (i) programming and execution
models~\cite{dino,ratchet,chain,alpaca} and (ii) architecture
mechanisms~\cite{hicks_isca_2017,idetic,nvp,tictpl}. While both approaches represent
progress, each has critical limitations. New architectures require costly
hardware changes and are inapplicable to today's embedded off-the-shelf
systems~\cite[Fig.  3]{hicks_isca_2017}~\cite[Fig. 9]{nvp}. New programming
models and compilers force programmers to change behavior~\cite{chain,ratchet},
inhibiting adoption.  New memory models may require more accesses to
non-volatile memory (for multi-versioning)~\cite{dino,chain} or may preclude
the use of volatile memory~\cite{ratchet}.  Effective use of both volatile and
non-volatile memory is important for efficiency, because volatile memory has
higher access energy and latency than SRAM~\cite[Fig. 4]{nvp}, and generality,
because devices often have much more FRAM than SRAM (e.g., 64 times
more~\cite{wolverine}). Hardware is effective, but inapplicable to existing
devices, making programming and execution models essential to the success of
intermittent computing. 
%Despite the limitations, we conjecture that programming
%and execution models will be a {\em de facto choice for sustaining data
%consistency} of intermittently-powered devices. Simply put, programming model
%does not require any hardware investment and is dependent only upon the
%programmer's skills.

Recent work~\cite{alpaca,chain} proposed {\em task-based} programming and
execution models in which the programmer statically decomposes their program
into a collection of tasks.  Tasks can include arbitrary computation and, upon
completion, are guaranteed to have executed {\em atomically}, despite
arbitrarily-timed power failures. 
%
The programmer explicitly expresses task-to-task control flow, which may be
conditionally input-dependent~\cite[Fig. 4]{chain}. An important programming
challenge presented by a task-based model is that the length of a software task's execution
is limited by the fixed, total amount of energy that a device can buffer in
hardware.  A task's code is static, but the duration of its execution
may be input-dependent and is difficult to predict.
%
Assuming that input power is negligible compared to operating
power~\cite{wisp}, a task will never be able to complete if its execution
consumes more energy than the system can buffer, creating the potential for
long tasks to be irreparably non-terminating.  On the other hand, transitioning
from one task to another imposes a run time cost and excessively small tasks
are inefficient. 

The key research question addressed by this work is to determine how to define
and execute tasks efficiently and avoid non-termination, given an unknown
energy buffer size and energy arrival process. In particular, we ask (i) how to
use software support to dynamically adapt the effective size of a task, while
still respecting programmer-specified task atomicity, and (ii) how to minimize
run time and energy consumption while automatically maintaining memory
consistency during execution?

\TODO{This is the main pitch statement.  we should all agree that this is what
\sys does.} In this work we develop {\bf \sys}: a new programming and execution
model that efficiently executes tasks and avoids non-termination across a range
of energy buffer sizes, without burdening the programmer.
%
To accomplish this goal, \sys introduces three new capabilities: {\em automatic
task compilation} that compiles arbitrary C code into tasks, {\em dynamic task
coalescing} that efficiently executes tasks without exceeding available energy,
and {\em volatile memory virtualization} that efficiently leverages both
volatile and non-volatile memory.  
%
\sys's compiler transforms arbitrary C code into a graph of tasks that reflects
the original program's control- and data-flow constraints.  The compiler
identifies data shared by multiple of the newly created tasks and instruments
reads and writes of those data so that \sys's memory virtualization mechanism
keeps those data consistent.
%
\sys's memory virtualization mechanism uses SRAM as working memory, that \sys
dynamically populates with pages of data from FRAM on demand during a task's
execution.  When a task ends, \sys commits dirty pages to FRAM using efficient
DMA block copies, ensuring task atomicity and memory consistency.
%
\sys's task coalescing mechanism executes multiple statically defined tasks
together as a single dynamic task. A programmer can specify small tasks that
will execute on a device with a small energy buffer. Coalescing tasks allows
running the same tasks on a device with a larger energy buffer, while avoiding
run time overheads associated with ending one task and beginning another.  
%

%~\cite{kistler_micro_2006} This reference will confuse people familiar with DMA.  DMA is well known I think we should cite the MCU datasheet, or use no cite. 
%
\todo{articulate this last point better}{Przemek}

To summarize, this work makes the following contributions:
%
\TODO{I think these are all much too long, given the depth of the intro and background already.  I suggest we cut to the barest minimum.}
\begin{enumerate}
%
\item {\bf Task coalescing mechanism:} \sys's core contribution is the introduction of dynamic task coalescing mechanism. It allows the programmer or a compiler to intuitively decompose the program into small tasks that amortize fixed per-task overheads, yet present no risk of exceeding device energy capacity. As such a decomposition executes, \sys~{\em coalesces dynamically} consecutive tasks. Coalescing elides the commits of coalesced tasks by buffering multiple tasks' updates in an FRAM commit buffer. Periodically, as the span of the coalesced task grows, \sys ends coalescing and commits the state of the coalesced task. If a power failure interrupts a sequence of coalesced tasks, \sys adaptively reduces the number of tasks in that sequence that it will coalesce, committing sooner in future executions. Consequently, \sys's coalescing mechanism allows a program to execute efficiently across a range of energy buffer sizes, avoiding transition overheads in larger buffers, and ensuring progress in smaller buffers.
%
\todo{Provide numerical results for this section}{Przemek}

\item {\bf Compiler-support automatic task generation:} second \sys's core contribution is the ability to split standard C programs into \sys's compatible tasks, effectively circumventing the need for labour-intensive manual task generation of the state of the art solutions~\cite{chain,alpaca}.
%
\todo{Elaborate on this more and provide numerical results}{Przemek}
%
\item {\bf Evaluation of data swapping strategies:} We propose and explore two data swapping strategies for intermittently-powered systems based on FRAM/SRAM architecture. The first strategy is {\em demand paging}, which swaps the SRAM page with a new page from FRAM, buffering the swapped-out page until commit. The second strategy is {\em buffered direct access}, which directly reads and writes FRAM relying on dynamic double-buffering to ensure memory is consistent at
commit. 
%
\todo{Once paging is fully implemented--update the paragraph}{Przemek}
\todo{Provide numerical results for this section}{Przemek}
%
\item {\bf Extensive \sys evaluation:} We evaluated \sys end-to-end on a collection of existing benchmark programs~\cite[Sec. 5]{chain} and new ones (including realistic case study of battery-less embedded sound detector) in a laboratory environment, and compare directly to state-of-the art task-based runtime~\cite{chain}, showing that \sys has high performance and can flexible target a variety of platforms without recompiling the code. 
%
\todo{add detailed text about evaluation results}{Przemek}
\todo{decide if we want to make this a contribution paragraph or not (then, put it as a closing paragraph)}{Brandon}
%
\end{enumerate}
